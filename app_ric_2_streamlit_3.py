import streamlit as st
import pandas as pd
from ultralytics import YOLO
import os
import shutil
import re
import plotly.express as px
from PIL import Image
import io
import zipfile
import requests

# Configura√ß√£o da p√°gina do Streamlit
st.set_page_config(
    page_title="An√°lise RCF - Imagens RIV",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Fun√ß√µes auxiliares para download de arquivos do Google Drive ---
def download_file_from_google_drive(file_id, destination):
    """
    Baixa um arquivo do Google Drive a partir do seu ID.
    """
    URL = "https://docs.google.com/uc?export=download"
    
    session = requests.Session()
    
    response = session.get(URL, params={'id': file_id}, stream=True)
    token = get_confirm_token(response)
    
    if token:
        params = {'id': file_id, 'confirm': token}
        response = session.get(URL, params=params, stream=True)
    
    with open(destination, "wb") as f:
        # Itera sobre o conte√∫do do arquivo para baix√°-lo em peda√ßos
        for chunk in response.iter_content(32768):
            if chunk:  # Filtra pacotes vazios
                f.write(chunk)
                
def get_confirm_token(response):
    """
    Extrai o token de confirma√ß√£o de download de arquivos grandes.
    """
    for key, value in response.cookies.items():
        if key.startswith('download_warning'):
            return value
    return None

# --- IDs dos modelos no Google Drive ---
# Extra√≠dos dos links fornecidos
MODEL_F1_ID = "10Hh3ovvDBurmD8wZYG7uRpZklMhPHo1u"
MODEL_F2_ID = "1It73Ji3ivybC2p-8b0Lr6BIAXdn_5eyf"

# Nomes locais dos arquivos
path_modelo_f1 = "fase_1.pt"
path_modelo_f2 = "fase_2.pt"

# --- Fun√ß√µes do seu c√≥digo original (adaptadas) ---
def run_yolo_predictions(path_modelo_f1, path_modelo_f2, src_dir, path_res, pasta_inferencia, arq_inferencia):
    """
    Executa as predi√ß√µes YOLO para as duas fases a partir de um diret√≥rio de origem.
    """
    with st.spinner('Executando a infer√™ncia YOLO...'):
        try:
            os.makedirs(os.path.join(path_res, pasta_inferencia), exist_ok=True)
            os.makedirs(os.path.join(path_res, arq_inferencia), exist_ok=True)

            model_f1 = YOLO(path_modelo_f1)
            model_f1.predict(source=src_dir, save=True, save_crop=True, project=path_res, name=pasta_inferencia, exist_ok=True)
            
            caminho_crops = os.path.join(path_res, pasta_inferencia, 'crops', 'Trilho')
            
            if not os.path.exists(caminho_crops) or not os.listdir(caminho_crops):
                return "Aviso: Nenhuma detec√ß√£o de trilho na Fase 1. A pasta de crops est√° vazia. N√£o √© poss√≠vel executar a Fase 2."

            model_f2 = YOLO(path_modelo_f2)
            model_f2.predict(source=caminho_crops, save=True, save_crop=True, project=path_res, name=arq_inferencia, exist_ok=True)

            return "Infer√™ncia YOLO conclu√≠da com sucesso para ambas as fases."
        except Exception as e:
            return f"Erro durante a infer√™ncia YOLO: {e}"

def processar_arquivos(diretorio_principal):
    """
    Processa os arquivos em um diret√≥rio e seus subdiret√≥rios,
    extraindo as informa√ß√µes do nome e criando um DataFrame.
    """
    dados = []
    avisos = []
    for root, dirs, files in os.walk(diretorio_principal):
        for file in files:
            match = re.match(
                r"^(?P<lim_sup>\d+)\s+-\s+(?P<lim_inf>\d+)\s*(?P<linha>[A-Z\d]+)_(?P<patio>[A-Za-z]+)_(?P<data>\d{8})_(?P<km>\d+)_(?P<metro>\d+)\.jpg$",
                file
            )
            
            if not match:
                avisos.append(f"Aviso: O arquivo '{file}' n√£o segue o padr√£o esperado e foi ignorado.")
                continue

            try:
                lim_sup = int(match.group('lim_sup'))
                lim_inf = int(match.group('lim_inf'))
                linha = match.group('linha')
                patio = match.group('patio')
                data_str = match.group('data')
                km = int(match.group('km'))
                metro = int(match.group('metro'))
                
                data_obj = pd.to_datetime(data_str, format='%Y%m%d')
                
                dados.append({
                    'LIM_sup': lim_sup,
                    'LIM_inf': lim_inf,
                    'Linha': linha,
                    'P√°tio': patio,
                    'Ano': data_obj.year,
                    'M√™s': data_obj.month,
                    'Dia': data_obj.day,
                    'KM': km,
                    'Metro': metro,
                    'Classifica√ß√£o': os.path.basename(root)
                })
            except (IndexError, AttributeError, ValueError) as e:
                avisos.append(f"Erro ao processar arquivo '{file}': {e}. Foi ignorado.")
                continue

    df = pd.DataFrame(dados)
    return df, avisos

# --- Layout e L√≥gica do Aplicativo Streamlit ---
st.title("An√°lise de RCF - Imagens RIV")
st.markdown("---")
st.header("Upload dos Dados")

uploaded_zip_file = st.file_uploader("Carregue as imagens em um arquivo .zip", type=["zip"])

st.markdown("---")

if st.button('Executar An√°lise', type='primary'):
    if not uploaded_zip_file:
        st.error("Por favor, carregue o arquivo .zip com as imagens para a an√°lise.")
    else:
        st.subheader("Status da Execu√ß√£o")
        
        temp_dir = "temp_data"
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
        os.makedirs(temp_dir)

        try:
            # Baixa os modelos do Google Drive
            with st.spinner("Baixando os modelos..."):
                download_file_from_google_drive(MODEL_F1_ID, path_modelo_f1)
                download_file_from_google_drive(MODEL_F2_ID, path_modelo_f2)
            st.info("Modelos baixados com sucesso.")

            # Descompacta o arquivo .zip de imagens
            src_dir = os.path.join(temp_dir, "uploaded_images")
            os.makedirs(src_dir)
            with zipfile.ZipFile(uploaded_zip_file, 'r') as zip_ref:
                zip_ref.extractall(src_dir)

            st.info("Arquivos de imagens carregados e descompactados com sucesso. Iniciando a an√°lise...")
            
            # Executa a infer√™ncia YOLO
            path_res = os.path.join(temp_dir, "resultado")
            yolo_status = run_yolo_predictions(path_modelo_f1, path_modelo_f2, src_dir, path_res, 'inferencia', 'resultado_final')
            st.info(yolo_status)
            
            if "Erro" not in yolo_status and "Aviso" not in yolo_status:
                path_res_modelo = os.path.join(path_res, 'resultado_final', 'crops')
                
                if os.path.exists(path_res_modelo):
                    df, avisos_processamento = processar_arquivos(path_res_modelo)
                    
                    if avisos_processamento:
                        st.warning("Houve avisos durante o processamento de arquivos:")
                        for aviso in avisos_processamento:
                            st.text(f"- {aviso}")

                    if not df.empty:
                        st.success("Processamento de arquivos conclu√≠do e DataFrame gerado.")
                        
                        st.subheader("Pr√©via do DataFrame")
                        st.dataframe(df)

                        st.subheader("Download dos Relat√≥rios")
                        
                        csv_buffer = io.StringIO()
                        df.to_csv(csv_buffer, index=False)
                        st.download_button(
                            label="üì• Baixar Relat√≥rio CSV",
                            data=csv_buffer.getvalue(),
                            file_name='relatorio.csv',
                            mime='text/csv',
                        )

                        xlsx_buffer = io.BytesIO()
                        df.to_excel(xlsx_buffer, index=False)
                        st.download_button(
                            label="üì• Baixar Relat√≥rio XLSX",
                            data=xlsx_buffer.getvalue(),
                            file_name='relatorio.xlsx',
                            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                        )
                        
                        st.subheader("An√°lises Visuais (Plotly)")

                        st.markdown("### Contagem de Classifica√ß√µes por P√°tio")
                        if 'Classifica√ß√£o' in df.columns and 'P√°tio' in df.columns:
                            classificacao_por_patio = df.groupby(['P√°tio', 'Classifica√ß√£o']).size().reset_index(name='Contagem')
                            fig_bar = px.bar(classificacao_por_patio, x='P√°tio', y='Contagem', color='Classifica√ß√£o', 
                                             title='Contagem de Defeitos por P√°tio')
                            st.plotly_chart(fig_bar, use_container_width=True)
                        else:
                            st.warning("Dados para a visualiza√ß√£o 'Classifica√ß√£o por P√°tio' n√£o est√£o dispon√≠veis no DataFrame.")
                        
                        st.markdown("### Distribui√ß√£o de Defeitos ao Longo dos KMs")
                        if 'KM' in df.columns and 'Classifica√ß√£o' in df.columns:
                            fig_scatter = px.scatter(df, x='KM', y='Metro', color='Classifica√ß√£o', 
                                                     title='Localiza√ß√£o de Defeitos por KM e Metro')
                            st.plotly_chart(fig_scatter, use_container_width=True)
                        else:
                            st.warning("Dados para a visualiza√ß√£o 'Distribui√ß√£o de Defeitos' n√£o est√£o dispon√≠veis no DataFrame.")
                    else:
                        st.warning("O DataFrame est√° vazio. Nenhum arquivo processado ou com dados v√°lidos.")
                else:
                    st.error("O diret√≥rio de resultados da Fase 2 n√£o foi encontrado.")
        finally:
            # Limpa todos os arquivos tempor√°rios, incluindo os modelos baixados
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
            if os.path.exists(path_modelo_f1):
                os.remove(path_modelo_f1)
            if os.path.exists(path_modelo_f2):
                os.remove(path_modelo_f2)
            st.info("Arquivos tempor√°rios limpos.")
            